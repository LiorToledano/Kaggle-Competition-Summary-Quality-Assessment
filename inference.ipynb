{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.026525,"end_time":"2022-02-08T11:42:51.944085","exception":false,"start_time":"2022-02-08T11:42:51.91756","status":"completed"},"tags":[]},"source":["# CFG"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:22:35.774999Z","iopub.status.busy":"2023-07-12T20:22:35.774567Z","iopub.status.idle":"2023-07-12T20:22:35.782442Z","shell.execute_reply":"2023-07-12T20:22:35.781229Z","shell.execute_reply.started":"2023-07-12T20:22:35.774944Z"},"papermill":{"duration":0.031276,"end_time":"2022-02-08T11:42:51.991958","exception":false,"start_time":"2022-02-08T11:42:51.960682","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    num_workers=4\n","    path=\"../input/deberta-v3-base-commonlit/\"\n","    config_path=path+'config.pth'\n","    model=\"microsoft/deberta-v3-large\"\n","    gradient_checkpointing=False\n","    batch_size=64\n","    target_cols=['content', 'wording']\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.015324,"end_time":"2022-02-08T11:42:52.022769","exception":false,"start_time":"2022-02-08T11:42:52.007445","status":"completed"},"tags":[]},"source":["# Library"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:22:36.783358Z","iopub.status.busy":"2023-07-12T20:22:36.782892Z","iopub.status.idle":"2023-07-12T20:22:36.802308Z","shell.execute_reply":"2023-07-12T20:22:36.801327Z","shell.execute_reply.started":"2023-07-12T20:22:36.783324Z"},"papermill":{"duration":19.692613,"end_time":"2022-02-08T11:43:11.730777","exception":false,"start_time":"2022-02-08T11:42:52.038164","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizers.__version__: 0.13.3\n","transformers.__version__: 4.30.2\n","env: TOKENIZERS_PARALLELISM=false\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","from transformers import DataCollatorWithPadding\n","%env TOKENIZERS_PARALLELISM=false\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.017982,"end_time":"2022-02-08T11:43:11.767286","exception":false,"start_time":"2022-02-08T11:43:11.749304","status":"completed"},"tags":[]},"source":["# tokenizer"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:22:36.999272Z","iopub.status.busy":"2023-07-12T20:22:36.998368Z","iopub.status.idle":"2023-07-12T20:22:37.430173Z","shell.execute_reply":"2023-07-12T20:22:37.428682Z","shell.execute_reply.started":"2023-07-12T20:22:36.999229Z"},"papermill":{"duration":0.17588,"end_time":"2022-02-08T11:43:11.961555","exception":false,"start_time":"2022-02-08T11:43:11.785675","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.017596,"end_time":"2022-02-08T11:43:12.141759","exception":false,"start_time":"2022-02-08T11:43:12.124163","status":"completed"},"tags":[]},"source":["# Utils"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:22:37.432928Z","iopub.status.busy":"2023-07-12T20:22:37.432482Z","iopub.status.idle":"2023-07-12T20:22:37.450438Z","shell.execute_reply":"2023-07-12T20:22:37.448612Z","shell.execute_reply.started":"2023-07-12T20:22:37.432890Z"},"papermill":{"duration":0.030498,"end_time":"2022-02-08T11:43:12.189984","exception":false,"start_time":"2022-02-08T11:43:12.159486","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename='inference'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.01765,"end_time":"2022-02-08T11:43:12.225407","exception":false,"start_time":"2022-02-08T11:43:12.207757","status":"completed"},"tags":[]},"source":["# OOF"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:22:37.579224Z","iopub.status.busy":"2023-07-12T20:22:37.578673Z","iopub.status.idle":"2023-07-12T20:22:37.609692Z","shell.execute_reply":"2023-07-12T20:22:37.608677Z","shell.execute_reply.started":"2023-07-12T20:22:37.579180Z"},"papermill":{"duration":42.093803,"end_time":"2022-02-08T11:43:54.337033","exception":false,"start_time":"2022-02-08T11:43:12.24323","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Score: 0.4670  Scores: [0.3979851971315948, 0.5360034540441694]\n","Score: 0.4670  Scores: [0.3979851971315948, 0.5360034540441694]\n"]}],"source":["# ====================================================\n","# oof\n","# ====================================================\n","oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n","labels = oof_df[CFG.target_cols].values\n","preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","score, scores = get_score(labels, preds)\n","LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.021365,"end_time":"2022-02-08T11:43:54.379768","exception":false,"start_time":"2022-02-08T11:43:54.358403","status":"completed"},"tags":[]},"source":["# Data Loading"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:22:37.939927Z","iopub.status.busy":"2023-07-12T20:22:37.938329Z","iopub.status.idle":"2023-07-12T20:22:37.973889Z","shell.execute_reply":"2023-07-12T20:22:37.972406Z","shell.execute_reply.started":"2023-07-12T20:22:37.939850Z"},"papermill":{"duration":0.976773,"end_time":"2022-02-08T11:43:55.377719","exception":false,"start_time":"2022-02-08T11:43:54.400946","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["test.shape: (4, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>abc123</td>\n","      <td>Example text 1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>def789</td>\n","      <td>Example text 2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>abc123</td>\n","      <td>Example text 3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>def789</td>\n","      <td>Example text 4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id prompt_id            text\n","0  000000ffffff    abc123  Example text 1\n","1  111111eeeeee    def789  Example text 2\n","2  222222cccccc    abc123  Example text 3\n","3  333333dddddd    def789  Example text 4"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["submission.shape: (4, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id  content  wording\n","0  000000ffffff      0.0      0.0\n","1  111111eeeeee      0.0      0.0\n","2  222222cccccc      0.0      0.0\n","3  333333dddddd      0.0      0.0"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","test = pd.read_csv('../input/commonlit-evaluate-student-summaries/summaries_test.csv')\n","submission = pd.read_csv('../input/commonlit-evaluate-student-summaries/sample_submission.csv')\n","\n","print(f\"test.shape: {test.shape}\")\n","display(test.head())\n","print(f\"submission.shape: {submission.shape}\")\n","display(submission.head())"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:22:38.143979Z","iopub.status.busy":"2023-07-12T20:22:38.143562Z","iopub.status.idle":"2023-07-12T20:22:38.160503Z","shell.execute_reply":"2023-07-12T20:22:38.158866Z","shell.execute_reply.started":"2023-07-12T20:22:38.143932Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>tokenize_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>abc123</td>\n","      <td>Example text 1</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>def789</td>\n","      <td>Example text 2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>abc123</td>\n","      <td>Example text 3</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>def789</td>\n","      <td>Example text 4</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id prompt_id            text  tokenize_length\n","0  000000ffffff    abc123  Example text 1                5\n","1  111111eeeeee    def789  Example text 2                5\n","2  222222cccccc    abc123  Example text 3                5\n","3  333333dddddd    def789  Example text 4                5"]},"metadata":{},"output_type":"display_data"}],"source":["# sort by length to speed up inference\n","test['tokenize_length'] = [len(CFG.tokenizer(text)['input_ids']) for text in test['text'].values]\n","test = test.sort_values('tokenize_length', ascending=True).reset_index(drop=True)\n","display(test.head())"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.023373,"end_time":"2022-02-08T11:43:55.501283","exception":false,"start_time":"2022-02-08T11:43:55.47791","status":"completed"},"tags":[]},"source":["# Dataset"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:22:39.104894Z","iopub.status.busy":"2023-07-12T20:22:39.104369Z","iopub.status.idle":"2023-07-12T20:22:39.116244Z","shell.execute_reply":"2023-07-12T20:22:39.114394Z","shell.execute_reply.started":"2023-07-12T20:22:39.104853Z"},"papermill":{"duration":0.034236,"end_time":"2022-02-08T11:43:55.55924","exception":false,"start_time":"2022-02-08T11:43:55.525004","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text, \n","        return_tensors=None, \n","        add_special_tokens=True, \n","        #max_length=CFG.max_len,\n","        #pad_to_max_length=True,\n","        #truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TestDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        return inputs"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.023204,"end_time":"2022-02-08T11:43:55.605919","exception":false,"start_time":"2022-02-08T11:43:55.582715","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:22:39.466026Z","iopub.status.busy":"2023-07-12T20:22:39.465537Z","iopub.status.idle":"2023-07-12T20:22:39.485759Z","shell.execute_reply":"2023-07-12T20:22:39.484416Z","shell.execute_reply.started":"2023-07-12T20:22:39.465986Z"},"papermill":{"duration":0.036876,"end_time":"2022-02-08T11:43:55.666198","exception":false,"start_time":"2022-02-08T11:43:55.629322","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, 2)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.023567,"end_time":"2022-02-08T11:43:55.713142","exception":false,"start_time":"2022-02-08T11:43:55.689575","status":"completed"},"tags":[]},"source":["# inference"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:23:22.929054Z","iopub.status.busy":"2023-07-12T20:23:22.928569Z","iopub.status.idle":"2023-07-12T20:23:22.941039Z","shell.execute_reply":"2023-07-12T20:23:22.939452Z","shell.execute_reply.started":"2023-07-12T20:23:22.929011Z"},"papermill":{"duration":0.03136,"end_time":"2022-02-08T11:43:55.768189","exception":false,"start_time":"2022-02-08T11:43:55.736829","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ====================================================\n","# inference\n","# ====================================================\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":26,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-12T20:23:22.944948Z","iopub.status.busy":"2023-07-12T20:23:22.944442Z","iopub.status.idle":"2023-07-12T20:24:07.410241Z","shell.execute_reply":"2023-07-12T20:24:07.405502Z","shell.execute_reply.started":"2023-07-12T20:23:22.944901Z"},"papermill":{"duration":78.050495,"end_time":"2022-02-08T11:45:13.842076","exception":false,"start_time":"2022-02-08T11:43:55.791581","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"309dc9ca073e44278f199a51a8a12783","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n","    reader_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","    reader_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 240, in _feed\n","    writer_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7455089cab4e46b29e4529c9f0b5745e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n","    reader_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n","    reader_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    reader_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db660cb54af94f08ba79fef7f1e7a4b7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n","Exception ignored in: <function _ConnectionBase.__del__ at 0x78021e080c10>\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 132, in __del__\n","    reader_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"616d12256825413c976ada66b14d07ba","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n","Exception in thread QueueFeederThread:\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n","    reader_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","    reader_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","    reader_close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    self._close()\n","  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    _close(self._handle)\n","OSError: [Errno 9] Bad file descriptor\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self.run()\n","  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n","    self._target(*self._args, **self._kwargs)\n","  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n","    queue_sem.release()\n","ValueError: semaphore or lock released too many times\n"]}],"source":["test_dataset = TestDataset(CFG, test)\n","test_loader = DataLoader(test_dataset,\n","                         batch_size=CFG.batch_size,\n","                         shuffle=False,\n","                         collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n","                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","predictions = []\n","for fold in CFG.trn_fold:\n","    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n","    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location=torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","    prediction = inference_fn(test_loader, model, device)\n","    predictions.append(prediction)\n","    del model, state, prediction; gc.collect()\n","    torch.cuda.empty_cache()\n","predictions = np.mean(predictions, axis=0)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.027753,"end_time":"2022-02-08T11:45:13.90824","exception":false,"start_time":"2022-02-08T11:45:13.880487","status":"completed"},"tags":[]},"source":["# Submission"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T20:24:07.414444Z","iopub.status.busy":"2023-07-12T20:24:07.414055Z","iopub.status.idle":"2023-07-12T20:24:07.483704Z","shell.execute_reply":"2023-07-12T20:24:07.482197Z","shell.execute_reply.started":"2023-07-12T20:24:07.414406Z"},"papermill":{"duration":0.043913,"end_time":"2022-02-08T11:45:13.979564","exception":false,"start_time":"2022-02-08T11:45:13.935651","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>-1.292239</td>\n","      <td>-0.867047</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>-1.335204</td>\n","      <td>-0.868903</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>-1.296077</td>\n","      <td>-0.858204</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>-1.293199</td>\n","      <td>-0.853518</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id   content   wording\n","0  000000ffffff -1.292239 -0.867047\n","1  111111eeeeee -1.335204 -0.868903\n","2  222222cccccc -1.296077 -0.858204\n","3  333333dddddd -1.293199 -0.853518"]},"metadata":{},"output_type":"display_data"}],"source":["test[CFG.target_cols] = predictions\n","submission = submission.drop(columns=CFG.target_cols).merge(test[['student_id'] + CFG.target_cols], on='student_id', how='left')\n","display(submission.head())\n","submission[['student_id'] + CFG.target_cols].to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
