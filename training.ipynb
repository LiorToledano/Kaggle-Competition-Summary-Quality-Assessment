{"cells":[{"cell_type":"code","execution_count":null,"id":"58fa2a11","metadata":{},"outputs":[],"source":["import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007611,"end_time":"2023-07-12T18:57:05.749173","exception":false,"start_time":"2023-07-12T18:57:05.741562","status":"completed"},"tags":[]},"source":["# CFG"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:05.768495Z","iopub.status.busy":"2023-07-12T18:57:05.768214Z","iopub.status.idle":"2023-07-12T18:57:05.775499Z","shell.execute_reply":"2023-07-12T18:57:05.774494Z"},"papermill":{"duration":0.018034,"end_time":"2023-07-12T18:57:05.777672","exception":false,"start_time":"2023-07-12T18:57:05.759638","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    wandb=True\n","    experiment_num = 19\n","    competition='ESS'\n","    _wandb_kernel='lior-toledano'\n","    debug=False\n","    apex=True\n","    print_freq=50\n","    num_workers=0\n","    model='deberta-v3-large'#'' #'deberta-v3-large'# ##\"deberta-v3-large\" #\"microsoft/deberta-v3-base\" #\n","    gradient_checkpointing=True\n","    scheduler='cosine' #'cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=5\n","    encoder_lr=1.5e-5\n","    decoder_lr=1.5e-5#\n","    min_lr=5e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=4\n","    max_len=1024 #1280#512#1024\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    freezing = False\n","    pooling = 'GemText'\n","    target_cols=['content', 'wording']\n","    \n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    split_by_prompt = True\n","    stratified_split = False\n","    train=True\n","    valid_labels = None\n","    seed = 42 \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"]},{"cell_type":"markdown","id":"8d0fe9cf","metadata":{},"source":["# Directory settings"]},{"cell_type":"code","execution_count":null,"id":"cac61331","metadata":{},"outputs":[],"source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","import os\n","\n","OUTPUT_DIR = f'./results-{CFG.experiment_num}/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:05.795181Z","iopub.status.busy":"2023-07-12T18:57:05.793692Z","iopub.status.idle":"2023-07-12T18:57:05.801265Z","shell.execute_reply":"2023-07-12T18:57:05.800361Z"},"papermill":{"duration":0.017945,"end_time":"2023-07-12T18:57:05.803221","exception":false,"start_time":"2023-07-12T18:57:05.785276","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    WANDB_API_KEY = 'e66c52ac056b32db73736974f3f5494c974ed281'\n","    import wandb\n","\n","    try:\n","        wandb.login()#(key= WANDB_API_KEY)\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project=f'CommonLit - ESS ', \n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=f\"fold_experiment - (experiment - {CFG.experiment_num})\",\n","                     job_type=\"train\",\n","                     anonymous=anony)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007388,"end_time":"2023-07-12T18:57:05.818090","exception":false,"start_time":"2023-07-12T18:57:05.810702","status":"completed"},"tags":[]},"source":["# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:05.834229Z","iopub.status.busy":"2023-07-12T18:57:05.833930Z","iopub.status.idle":"2023-07-12T18:57:49.763324Z","shell.execute_reply":"2023-07-12T18:57:49.762133Z"},"papermill":{"duration":43.940064,"end_time":"2023-07-12T18:57:49.765590","exception":false,"start_time":"2023-07-12T18:57:05.825526","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","#os.system('pip install iterative-stratification==0.1.7')\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","#os.system('pip install -q transformers')\n","#os.system('pip install -q tokenizers')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from collections import Counter\n","import spacy\n","import re\n","from spellchecker import SpellChecker\n","import lightgbm as lgb\n","\n","\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"id":"6cc2c0a1","metadata":{},"outputs":[],"source":["lgb.__version__"]},{"cell_type":"code","execution_count":null,"id":"4e9a34d0","metadata":{},"outputs":[],"source":["tqdm.pandas()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007785,"end_time":"2023-07-12T18:57:49.781404","exception":false,"start_time":"2023-07-12T18:57:49.773619","status":"completed"},"tags":[]},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"id":"57229c41","metadata":{},"outputs":[],"source":["print(torch.cuda.is_available())\n","device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:49.798713Z","iopub.status.busy":"2023-07-12T18:57:49.798142Z","iopub.status.idle":"2023-07-12T18:57:49.818606Z","shell.execute_reply":"2023-07-12T18:57:49.817748Z"},"papermill":{"duration":0.031391,"end_time":"2023-07-12T18:57:49.820629","exception":false,"start_time":"2023-07-12T18:57:49.789238","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)"]},{"cell_type":"code","execution_count":null,"id":"0d15fc41","metadata":{},"outputs":[],"source":["spacy.load('en_core_web_sm')\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007898,"end_time":"2023-07-12T18:57:49.836243","exception":false,"start_time":"2023-07-12T18:57:49.828345","status":"completed"},"tags":[]},"source":["# Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:49.853252Z","iopub.status.busy":"2023-07-12T18:57:49.852568Z","iopub.status.idle":"2023-07-12T18:57:49.979501Z","shell.execute_reply":"2023-07-12T18:57:49.978626Z"},"papermill":{"duration":0.141389,"end_time":"2023-07-12T18:57:49.985355","exception":false,"start_time":"2023-07-12T18:57:49.843966","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv('./data/commonlit-evaluate-student-summaries/summaries_train.csv')\n","test = pd.read_csv('./data/commonlit-evaluate-student-summaries/summaries_test.csv')\n","submission = pd.read_csv('./data/commonlit-evaluate-student-summaries/sample_submission.csv')\n","DATA_DIR = \"data/commonlit-evaluate-student-summaries/\"\n","\n","prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n","prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n","summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n","summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n","sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n","\n","\n","# summaries_train = summaries_train.head(10) # for dev mode\n","\n","print(f\"train.shape: {summaries_train.shape}\")\n","display(summaries_train.head())\n","print(f\"test.shape: {summaries_test.shape}\")\n","display(summaries_test.head())\n","print(f\"submission.shape: {sample_submission.shape}\")\n","display(sample_submission.head())"]},{"cell_type":"code","execution_count":null,"id":"1242e3a5","metadata":{},"outputs":[],"source":["class Preprocessor:\n","    def __init__(self, \n","                model_name: str,\n","                ) -> None:\n","        self.tokenizer = AutoTokenizer.from_pretrained(f\"{model_name}\")\n","        self.STOP_WORDS = set(stopwords.words('english'))\n","        \n","        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n","        self.speller = SpellChecker() #Speller(lang='en')\n","        \n","    def count_text_length(self, df: pd.DataFrame, col:str) -> pd.Series:\n","        \"\"\" text length \"\"\"\n","        tokenizer=self.tokenizer\n","        return df[col].progress_apply(lambda x: len(tokenizer.encode(x)))\n","\n","    def word_overlap_count(self, row):\n","        \"\"\" intersection(prompt_text, text) \"\"\"        \n","        def check_is_stop_word(word):\n","            return word in self.STOP_WORDS\n","        \n","        prompt_words = row['prompt_tokens']\n","        summary_words = row['summary_tokens']\n","        if self.STOP_WORDS:\n","            prompt_words = list(filter(check_is_stop_word, prompt_words))\n","            summary_words = list(filter(check_is_stop_word, summary_words))\n","        return len(set(prompt_words).intersection(set(summary_words)))\n","            \n","    def ngrams(self, token, n):\n","        # Use the zip function to help us generate n-grams\n","        # Concatentate the tokens into ngrams and return\n","        ngrams = zip(*[token[i:] for i in range(n)])\n","        return [\" \".join(ngram) for ngram in ngrams]\n","\n","    def ngram_co_occurrence(self, row, n: int):\n","        # Tokenize the original text and summary into words\n","        original_tokens = row['prompt_tokens']\n","        summary_tokens = row['summary_tokens']\n","\n","        # Generate n-grams for the original text and summary\n","        original_ngrams = set(self.ngrams(original_tokens, n))\n","        summary_ngrams = set(self.ngrams(summary_tokens, n))\n","\n","        # Calculate the number of common n-grams\n","        common_ngrams = original_ngrams.intersection(summary_ngrams)\n","\n","        # # Optionally, you can get the frequency of common n-grams for a more nuanced analysis\n","        # original_ngram_freq = Counter(ngrams(original_words, n))\n","        # summary_ngram_freq = Counter(ngrams(summary_words, n))\n","        # common_ngram_freq = {ngram: min(original_ngram_freq[ngram], summary_ngram_freq[ngram]) for ngram in common_ngrams}\n","\n","        return len(common_ngrams)\n","    \n","    def ner_overlap_count(self, row, mode:str):\n","        model = self.spacy_ner_model\n","        def clean_ners(ner_list):\n","            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n","        prompt = model(row['prompt_text'])\n","        summary = model(row['text'])\n","\n","        if \"spacy\" in str(model):\n","            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n","            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n","        elif \"stanza\" in str(model):\n","            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n","            summary_ner = set([(token.text, token.type) for token in summary.ents])\n","        else:\n","            raise Exception(\"Model not supported\")\n","\n","        prompt_ner = clean_ners(prompt_ner)\n","        summary_ner = clean_ners(summary_ner)\n","\n","        intersecting_ners = prompt_ner.intersection(summary_ner)\n","        \n","        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n","        \n","        if mode == \"train\":\n","            return ner_dict\n","        elif mode == \"test\":\n","            return {key: ner_dict.get(key) for key in self.ner_keys}\n","\n","    \n","    def quotes_count(self, row):\n","        summary = row['text']\n","        text = row['prompt_text']\n","        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n","        if len(quotes_from_summary)>0:\n","            return [quote in text for quote in quotes_from_summary].count(True)\n","        else:\n","            return 0\n","\n","    def spelling(self, text):\n","        \n","        wordlist=text.split()\n","        amount_miss = len(list(self.speller.unknown(wordlist)))\n","\n","        return amount_miss\n","    \n","    def run(self, \n","            prompts: pd.DataFrame,\n","            summaries:pd.DataFrame,\n","            mode:str\n","        ) -> pd.DataFrame:\n","        \n","        # before merge preprocess\n","        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n","            lambda x: len(self.tokenizer.encode(x))\n","        )\n","        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n","            lambda x: self.tokenizer.convert_ids_to_tokens(\n","                self.tokenizer.encode(x), \n","                skip_special_tokens=True\n","            )\n","        )\n","\n","        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n","            lambda x: len(self.tokenizer.encode(x))\n","        )\n","        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n","            lambda x: self.tokenizer.convert_ids_to_tokens(\n","                self.tokenizer.encode(x), \n","                skip_special_tokens=True\n","            )\n","\n","        )\n","        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n","\n","        # merge prompts and summaries\n","        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n","\n","        # after merge preprocess\n","        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n","        \n","        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n","        input_df['bigram_overlap_count'] = input_df.progress_apply(\n","            self.ngram_co_occurrence,args=(2,), axis=1 \n","        )\n","        input_df['trigram_overlap_count'] = input_df.progress_apply(\n","            self.ngram_co_occurrence, args=(3,), axis=1\n","        )\n","        \n","        # Crate dataframe with count of each category NERs overlap for all the summaries\n","        # Because it spends too much time for this feature, I don't use this time.\n","#         ners_count_df  = input_df.progress_apply(\n","#             lambda row: pd.Series(self.ner_overlap_count(row, mode=mode), dtype='float64'), axis=1\n","#         ).fillna(0)\n","#         self.ner_keys = ners_count_df.columns\n","#         ners_count_df['sum'] = ners_count_df.sum(axis=1)\n","#         ners_count_df.columns = ['NER_' + col for col in ners_count_df.columns]\n","#         # join ner count dataframe with train dataframe\n","#         input_df = pd.concat([input_df, ners_count_df], axis=1)\n","        \n","        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n","        \n","        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n","    \n","preprocessor = Preprocessor(model_name=CFG.model)"]},{"cell_type":"code","execution_count":null,"id":"5c81b7a4","metadata":{},"outputs":[],"source":["train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n","test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n","\n","test.head()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00864,"end_time":"2023-07-12T18:57:50.003107","exception":false,"start_time":"2023-07-12T18:57:49.994467","status":"completed"},"tags":[]},"source":["# CV split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:50.021734Z","iopub.status.busy":"2023-07-12T18:57:50.021448Z","iopub.status.idle":"2023-07-12T18:57:50.332582Z","shell.execute_reply":"2023-07-12T18:57:50.331686Z"},"papermill":{"duration":0.322909,"end_time":"2023-07-12T18:57:50.334680","exception":false,"start_time":"2023-07-12T18:57:50.011771","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","\n","\n","if CFG.split_by_prompt:\n","    if CFG.stratified_split:\n","        \n","        train['fold'] = -1\n","        fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","        for n, (train_index, val_index) in enumerate(fold.split(train, train['prompt_id'])):\n","            train.loc[val_index, 'fold'] = n\n","    else:\n","        gkf = GroupKFold(n_splits=CFG.n_fold)\n","\n","        for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n","            train.loc[val_index, \"fold\"] = i\n","    \n","else:\n","    Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","    for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_cols])):\n","        train.loc[val_index, 'fold'] = int(n)\n","\n","train['fold'] = train['fold'].astype(int)\n","\n","display(train.groupby('fold').size())\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:50.353718Z","iopub.status.busy":"2023-07-12T18:57:50.353443Z","iopub.status.idle":"2023-07-12T18:57:50.358865Z","shell.execute_reply":"2023-07-12T18:57:50.357891Z"},"papermill":{"duration":0.017361,"end_time":"2023-07-12T18:57:50.360934","exception":false,"start_time":"2023-07-12T18:57:50.343573","status":"completed"},"tags":[]},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008559,"end_time":"2023-07-12T18:57:50.378324","exception":false,"start_time":"2023-07-12T18:57:50.369765","status":"completed"},"tags":[]},"source":["# tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:50.397779Z","iopub.status.busy":"2023-07-12T18:57:50.396980Z","iopub.status.idle":"2023-07-12T18:57:52.770741Z","shell.execute_reply":"2023-07-12T18:57:52.769710Z"},"papermill":{"duration":2.385784,"end_time":"2023-07-12T18:57:52.773141","exception":false,"start_time":"2023-07-12T18:57:50.387357","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009431,"end_time":"2023-07-12T18:57:52.792340","exception":false,"start_time":"2023-07-12T18:57:52.782909","status":"completed"},"tags":[]},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:52.812516Z","iopub.status.busy":"2023-07-12T18:57:52.812190Z","iopub.status.idle":"2023-07-12T18:57:55.168561Z","shell.execute_reply":"2023-07-12T18:57:55.167631Z"},"papermill":{"duration":2.369739,"end_time":"2023-07-12T18:57:55.171507","exception":false,"start_time":"2023-07-12T18:57:52.801768","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","# lengths = []\n","# tk0 = tqdm(train['text'].fillna(\"\").values, total=len(train))\n","# for text in tk0:\n","#     length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","#     lengths.append(length)\n","# CFG.max_len = max(lengths) + 2 # cls & sep\n","# LOGGER.info(f\"max_len: {CFG.max_len}\")\n","\n","\n","max_words_text = train[\"text\"].apply(lambda x: len(x.split())).max()\n","max_words_prompt_question = train[\"prompt_question\"].apply(lambda x: len(x.split())).max()\n","max_words_prompt_text = train[\"prompt_text\"].apply(lambda x: len(x.split())).max()\n"]},{"cell_type":"code","execution_count":null,"id":"901b89f8","metadata":{},"outputs":[],"source":["train.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:55.192740Z","iopub.status.busy":"2023-07-12T18:57:55.192458Z","iopub.status.idle":"2023-07-12T18:57:55.202840Z","shell.execute_reply":"2023-07-12T18:57:55.201949Z"},"papermill":{"duration":0.023109,"end_time":"2023-07-12T18:57:55.204841","exception":false,"start_time":"2023-07-12T18:57:55.181732","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","\n","\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text, \n","        return_tensors=None, \n","        add_special_tokens=True, \n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df[cfg.target_cols].values\n","        self.input_text_cols = [\"prompt_title\", \"prompt_question\", \"text\"]\n","        self.texts = df.apply(self.concatenate_with_sep_token, axis=1)  # Concatenate specified columns\n","        \n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        return {\n","            'input_ids': torch.tensor(ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(mask, dtype=torch.long),\n","            \n","        } , label\n","    \n","    def concatenate_with_sep_token(self, row):\n","        sep = \" \" + tokenizer.sep_token + \" \"\n","        text_cols = [row[col] for col in self.input_text_cols]\n","        return sep.join(text_cols)\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"]},{"cell_type":"code","execution_count":null,"id":"7c2531d5","metadata":{},"outputs":[],"source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","    \n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e9\n","        max_embeddings, _ = torch.max(embeddings, dim = 1)\n","        return max_embeddings\n","    \n","class MeanMax(nn.Module):\n","    def __init__(self):\n","        super(MeanMax, self).__init__()\n","        \n","        self.mean_pooler = MeanPooling()\n","        self.max_pooler  = MaxPooling()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        mean_pooler = self.mean_pooler( last_hidden_state ,attention_mask )\n","        max_pooler =  self.max_pooler( last_hidden_state ,attention_mask )\n","        out = torch.concat([mean_pooler ,max_pooler ] , 1)\n","        return out\n","    \n","class GeMText(nn.Module):\n","    def __init__(self, dim = 1, p=3, eps=1e-6):\n","        super(GeMText, self).__init__()\n","        self.dim = dim\n","        self.p = Parameter(torch.ones(1) * p)\n","        self.eps = eps\n","        self.feat_mult = 1\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.shape)\n","        x = (last_hidden_state.clamp(min=self.eps) * attention_mask_expanded).pow(self.p).sum(self.dim)\n","        ret = x / attention_mask_expanded.sum(self.dim).clip(min=self.eps)\n","        ret = ret.pow(1 / self.p)\n","        return ret\n","    \n","def get_pooling_layer():\n","    if CFG.pooling == 'Mean':\n","        return MeanPooling()\n","    \n","    elif CFG.pooling == 'Max':\n","        return MaxPooling()\n","    \n","    elif CFG.pooling == 'MeanMax':\n","        return MeanMax()\n","    \n","    elif CFG.pooling == 'GemText':\n","        return GeMText()\n","\n","\n","print(get_pooling_layer())\n","\n","def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","def odd_layer_freeze(module):\n","    for i in range(1,24,2):\n","        for n,p in module.encoder.layer[i].named_parameters():\n","            p.requires_grad = False\n","            \n","def even_layer_freeze(module):\n","    for i in range(0,24,2):\n","        for n,p in module.encoder.layer[i].named_parameters():\n","            p.requires_grad = False\n","            \n","def top_half_layer_freeze(module):\n","    for i in range(0,13,1):\n","        for n,p in module.encoder.layer[i].named_parameters():\n","            p.requires_grad = False\n","\n","def bottom_half_layer_freeze(module):\n","    for i in range(13,14,1):\n","        for n,p in module.encoder.layer[i].named_parameters():\n","            p.requires_grad = False"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009564,"end_time":"2023-07-12T18:57:55.224029","exception":false,"start_time":"2023-07-12T18:57:55.214465","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","execution_count":null,"id":"f8870766","metadata":{},"outputs":[],"source":["class BaselineModel(nn.Module):\n","    def __init__(self, model_name):\n","        super(BaselineModel, self).__init__()\n","        \n","        self.model = AutoModel.from_pretrained(model_name)\n","        self.config = AutoConfig.from_pretrained(model_name)\n","        #self.drop = nn.Dropout(p=0.1)\n","        self.pooler = get_pooling_layer()\n","\n","        if CFG.pooling == 'MeanMax':\n","            self.fc = nn.Linear(2*self.config.hidden_size, 2)\n","        else:\n","            self.fc = nn.Linear(self.config.hidden_size, 2)\n","            \n","        \n","        self._init_weights(self.fc)\n","        \n","        if CFG.freezing:\n","            top_half_layer_freeze(self.model)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","           \n","    def forward(self, ids, mask):\n","        out = self.model(input_ids=ids,attention_mask=mask,\n","                         output_hidden_states=False)\n","        out = self.pooler(out.last_hidden_state, mask)\n","        #out = self.drop(out)\n","        outputs = self.fc(out)\n","        return outputs"]},{"cell_type":"code","execution_count":null,"id":"53955f94","metadata":{},"outputs":[],"source":["# class BaselineModel(nn.Module):\n","#     def __init__(self, model_name):\n","#         super(BaselineModel, self).__init__()\n","        \n","#         self.model = AutoModel.from_pretrained(model_name)\n","#         self.config = AutoConfig.from_pretrained(model_name)\n","#         self.num_of_pollers = 3\n","#         #self.poolers = nn.ModuleList([get_pooling_layer() for _ in range(self.num_of_pollers)])  # Create a list of poolers\n","#         self.poolers = nn.ModuleList([MeanPooling(), MaxPooling(), GeMText()])  # Create a list of poolers\n","        \n","\n","#         if CFG.pooling == 'MeanMax':\n","#             self.fc = nn.Linear(2 * self.config.hidden_size, 2)\n","#         else:\n","#             self.fc = nn.Linear(self.num_of_pollers * self.config.hidden_size, 2)\n","            \n","#         self._init_weights(self.fc)\n","        \n","#         if CFG.freezing:\n","#             top_half_layer_freeze(self.model)\n","        \n","#     def _init_weights(self, module):\n","#         if isinstance(module, nn.Linear):\n","#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","#             if module.bias is not None:\n","#                 module.bias.data.zero_()\n","#         elif isinstance(module, nn.Embedding):\n","#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","#             if module.padding_idx is not None:\n","#                 module.weight.data[module.padding_idx].zero_()\n","#         elif isinstance(module, nn.LayerNorm):\n","#             module.bias.data.zero_()\n","#             module.weight.data.fill_(1.0)\n","           \n","#     def forward(self, ids, mask):\n","#         out = self.model(input_ids=ids, attention_mask=mask, output_hidden_states=False)\n","        \n","#         # Apply each pooler to the last hidden state\n","#         pooled_outputs = [pooler(out.last_hidden_state, mask) for pooler in self.poolers]\n","        \n","#         # Concatenate the pooled outputs along dimension 1\n","#         out = torch.cat(pooled_outputs, dim=1)\n","        \n","#         outputs = self.fc(out)\n","#         return outputs\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:55.244581Z","iopub.status.busy":"2023-07-12T18:57:55.244302Z","iopub.status.idle":"2023-07-12T18:57:55.259175Z","shell.execute_reply":"2023-07-12T18:57:55.258355Z"},"papermill":{"duration":0.027453,"end_time":"2023-07-12T18:57:55.261060","exception":false,"start_time":"2023-07-12T18:57:55.233607","status":"completed"},"tags":[]},"outputs":[],"source":["# # ====================================================\n","# # Model\n","# # ====================================================\n","import torch.nn.functional as F\n","\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.007\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.007\n","            #self.config.max_position_embeddings = 1024\n","            self.config.num_labels = 2\n","            self.config.update({\n","            \"problem_type\": \"regression\"\n","        })\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        self.pool = MeanPooling()\n","        \n","        \n","\n","        self.hidden_layer1 = nn.Linear(self.config.hidden_size, 512)\n","        self.hidden_layer2 = nn.Linear(512, 256)\n","        # Attention layer parameters\n","        self.num_heads = 4  # You can adjust the number of attention heads\n","        self.attention_dim = 64  # You can adjust the attention dimension\n","\n","        # Attention layer\n","        self.attention = nn.MultiheadAttention(256, self.num_heads, 0.007)\n","        \n","        self.fc = nn.Linear(256, 2)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        output = self.model(**inputs)\n","        # feature = self.feature(inputs)\n","        # hidden1_output = F.relu(self.hidden_layer1(feature))\n","        # hidden2_output = F.relu(self.hidden_layer2(hidden1_output))\n","\n","        # # Apply attention to the hidden2_output\n","        # attention_output, _ = self.attention(hidden2_output, hidden2_output, hidden2_output)\n","        # output = self.fc(attention_output)\n","        return output"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009443,"end_time":"2023-07-12T18:57:55.280318","exception":false,"start_time":"2023-07-12T18:57:55.270875","status":"completed"},"tags":[]},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:55.301603Z","iopub.status.busy":"2023-07-12T18:57:55.300802Z","iopub.status.idle":"2023-07-12T18:57:55.307792Z","shell.execute_reply":"2023-07-12T18:57:55.306966Z"},"papermill":{"duration":0.019731,"end_time":"2023-07-12T18:57:55.309674","exception":false,"start_time":"2023-07-12T18:57:55.289943","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# Loss\n","# ====================================================\n","class RMSELoss(nn.Module):\n","    def __init__(self, reduction='mean', eps=1e-9):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction='none')\n","        self.reduction = reduction\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true):\n","        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss\n","    \n","class MSELoss(nn.Module):\n","    def __init__(self, reduction='mean'):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction=reduction)\n","\n","    def forward(self, y_pred, y_true):\n","        return self.mse(y_pred, y_true)\n","\n","\n","class MAELoss(nn.Module):\n","    def __init__(self, reduction='mean'):\n","        super().__init__()\n","        self.mae = nn.L1Loss(reduction=reduction)\n","\n","    def forward(self, y_pred, y_true):\n","        return self.mae(y_pred, y_true)\n","\n","class HuberLoss(nn.Module):\n","    def __init__(self, delta=1.0, reduction='mean'):\n","        super().__init__()\n","        self.huber = nn.SmoothL1Loss(reduction=reduction)\n","        self.delta = delta\n","\n","    def forward(self, y_pred, y_true):\n","        return self.huber(y_pred, y_true * self.delta)\n","\n","class PoissonLoss(nn.Module):\n","    def __init__(self, log_input=True, full=False, reduction='mean'):\n","        super().__init__()\n","        self.poisson = nn.PoissonNLLLoss(log_input=log_input, full=full, reduction=reduction)\n","\n","    def forward(self, y_pred, y_true):\n","        return self.poisson(y_pred, y_true)\n","\n","class KLDivLoss(nn.Module):\n","    def __init__(self, reduction='mean'):\n","        super().__init__()\n","        self.kl_loss = nn.KLDivLoss(reduction=reduction)\n","\n","    def forward(self, y_pred, y_true):\n","        return self.kl_loss(F.log_softmax(y_pred, dim=-1), F.softmax(y_true, dim=-1))\n","#Contrastive Loss (for siamese networks or similarity learning):\n","\n","class ContrastiveLoss(nn.Module):\n","    def __init__(self, margin=1.0):\n","        super().__init__()\n","        self.margin = margin\n","\n","    def forward(self, output1, output2, target):\n","        euclidean_distance = F.pairwise_distance(output1, output2)\n","        loss_contrastive = torch.mean((1 - target) * torch.pow(euclidean_distance, 2) +\n","                                      (target) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n","        return loss_contrastive"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009512,"end_time":"2023-07-12T18:57:55.328765","exception":false,"start_time":"2023-07-12T18:57:55.319253","status":"completed"},"tags":[]},"source":["# Helpler functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:55.349280Z","iopub.status.busy":"2023-07-12T18:57:55.349032Z","iopub.status.idle":"2023-07-12T18:57:55.369160Z","shell.execute_reply":"2023-07-12T18:57:55.368229Z"},"papermill":{"duration":0.032719,"end_time":"2023-07-12T18:57:55.371176","exception":false,"start_time":"2023-07-12T18:57:55.338457","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, valid_loader = None):\n","    \n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        ids  =  inputs['input_ids'].to(device, dtype = torch.long)\n","        mask = inputs['attention_mask'].to(device, dtype = torch.long)\n","        # for k, v in inputs.items():\n","        #     inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(ids, mask)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","\n","        if (global_step % 100 == 0) and (global_step > 0):\n","            # Perform validation every 100 steps\n","            start_time = time.time()\n","            avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","            # scoring\n","            score, scores = get_score(CFG.valid_labels, predictions)\n","\n","            elapsed = time.time() - start_time\n","\n","            LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","            if CFG.wandb:\n","                wandb.log({f\"[fold{fold}] steps\": global_step,\n","                        f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                        f\"[fold{fold}] score\": score})\n","            \n","            if CFG.best_score > score:\n","                CFG.best_score = score\n","                LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {CFG.best_score:.4f} Model')\n","                torch.save({'model': model.state_dict(),\n","                            'predictions': predictions},\n","                            OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","            \n","            # Continue training\n","            model.train()\n","            \n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        ids  =  inputs['input_ids'].to(device, dtype = torch.long)\n","        mask = inputs['attention_mask'].to(device, dtype = torch.long)\n","        # for k, v in inputs.items():\n","        #     inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(ids, mask)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009719,"end_time":"2023-07-12T18:57:55.390452","exception":false,"start_time":"2023-07-12T18:57:55.380733","status":"completed"},"tags":[]},"source":["# train loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:55.411092Z","iopub.status.busy":"2023-07-12T18:57:55.410830Z","iopub.status.idle":"2023-07-12T18:57:55.429905Z","shell.execute_reply":"2023-07-12T18:57:55.428925Z"},"papermill":{"duration":0.032097,"end_time":"2023-07-12T18:57:55.432214","exception":false,"start_time":"2023-07-12T18:57:55.400117","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","    run_name = f\"fold_{fold }\"  # Create a unique run name for each fold\n","    wandb.init(project=f'CommonLit - ESS (experiment - {CFG.experiment_num})', \n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=run_name,\n","                     job_type=\"train\",\n","                     anonymous=anony)\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","    CFG.valid_labels = valid_folds[CFG.target_cols].values\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","    \n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = BaselineModel(CFG.model)# CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.SmoothL1Loss(reduction='mean') #HuberLoss()#nn.SmoothL1Loss(reduction='mean') # RMSELoss(reduction=\"mean\")\n","    \n","    CFG.best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, valid_loader=valid_loader)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score, scores = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if CFG.best_score > score:\n","            CFG.best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {CFG.best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T18:57:55.452565Z","iopub.status.busy":"2023-07-12T18:57:55.452309Z","iopub.status.idle":"2023-07-12T20:01:56.828686Z","shell.execute_reply":"2023-07-12T20:01:56.827757Z"},"papermill":{"duration":3841.388987,"end_time":"2023-07-12T20:01:56.830869","exception":false,"start_time":"2023-07-12T18:57:55.441882","status":"completed"},"tags":[]},"outputs":[],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target_cols].values\n","        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","        score, scores = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()"]},{"cell_type":"code","execution_count":null,"id":"f6cb890f","metadata":{},"outputs":[],"source":["oof_df = pd.read_pickle(OUTPUT_DIR+'oof_df.pkl')"]},{"cell_type":"code","execution_count":null,"id":"84d0fe16","metadata":{},"outputs":[],"source":["targets = [\"content\", \"wording\"]\n","\n","drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \n","                \"prompt_question\", \"prompt_title\", \n","                \"prompt_text\"\n","               ] + targets\n","\n","train = oof_df"]},{"cell_type":"code","execution_count":null,"id":"8d38fda5","metadata":{},"outputs":[],"source":["model_dict = {}\n","\n","for target in targets:\n","    models = []\n","    \n","    for fold in range(CFG.n_fold):\n","\n","        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n","        y_train_cv = train[train[\"fold\"] != fold][target]\n","\n","        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n","        y_eval_cv = train[train[\"fold\"] == fold][target]\n","\n","        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n","        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n","\n","        params = {\n","                  'boosting_type': 'gbdt',\n","                  'random_state': 42,\n","                  'objective': 'regression',\n","                  'metric': 'rmse',\n","                  'learning_rate': 0.05,\n","                  }\n","\n","        evaluation_results = {}\n","        model = lgb.train(params,\n","                          num_boost_round=10000,\n","                            #categorical_feature = categorical_features,\n","                          valid_names=['train', 'valid'],\n","                          train_set=dtrain,\n","                          valid_sets=dval,\n","                          callbacks=[\n","                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n","                               lgb.log_evaluation(100),\n","                              lgb.callback.record_evaluation(evaluation_results)\n","                            ],\n","                          )\n","        models.append(model)\n","    \n","    model_dict[target] = models\n"]},{"cell_type":"code","execution_count":null,"id":"f857fe2c","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b3f2646d","metadata":{},"outputs":[],"source":["import joblib\n","\n","for target, models in model_dict.items():\n","    for fold, model in enumerate(models):\n","        # Define a unique filename for each model\n","        filename = f'{target}_model_fold_{fold}.pkl'\n","        model_dir = OUTPUT_DIR +'lgbm'\n","        if not os.path.exists(model_dir):\n","            os.makedirs(model_dir)\n","        full_path = model_dir +'/' + filename\n","    \n","        # Save the model to a file\n","        joblib.dump(model, filename)\n"]},{"cell_type":"code","execution_count":null,"id":"a72c0732","metadata":{},"outputs":[],"source":["# cv\n","rmses = []\n","LOGGER.info(f\"CV - With lgbm\")\n","for target in targets:\n","    models = model_dict[target]\n","\n","    preds = []\n","    trues = []\n","    \n","    for fold, model in enumerate(models):\n","        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n","        y_eval_cv = train[train[\"fold\"] == fold][target]\n","\n","        pred = model.predict(X_eval_cv)\n","\n","        trues.extend(y_eval_cv)\n","        preds.extend(pred)\n","        \n","    rmse = np.sqrt(mean_squared_error(trues, preds))\n","    print(f\"{target}_rmse : {rmse}\")\n","    LOGGER.info(f\"{target}_rmse : {rmse}\")\n","    rmses = rmses + [rmse]\n","\n","print(f\"mcrmse : {sum(rmses) / len(rmses)}\")\n","LOGGER.info(f\"mcrmse : {sum(rmses) / len(rmses)}\")"]},{"cell_type":"code","execution_count":null,"id":"0cab5b90","metadata":{},"outputs":[],"source":["from catboost import CatBoostRegressor\n","\n","\n","model_dict_2 = {}\n","for target in targets:\n","    models = []\n","    \n","    for fold in range(CFG.n_fold):\n","\n","        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n","        y_train_cv = train[train[\"fold\"] != fold][target]\n","\n","        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n","        y_eval_cv = train[train[\"fold\"] == fold][target]\n","\n","        model = CatBoostRegressor(\n","            learning_rate = 0.048,\n","            depth = 4,\n","            min_data_in_leaf = 34,\n","            iterations = 10000,\n","            task_type ='GPU',\n","            loss_function ='RMSE'\n","          )\n","        model.fit(X_train_cv, \n","                  y_train_cv, \n","                  eval_set=[(X_eval_cv, y_eval_cv)],\n","                  verbose=False)\n","        models.append(model)\n","\n","    model_dict_2[target] = models"]},{"cell_type":"code","execution_count":null,"id":"64cdb271","metadata":{},"outputs":[],"source":["rmses = []\n","\n","for target in targets:\n","    models = model_dict_2[target]\n","\n","    preds = []\n","    trues = []\n","    \n","    for fold, model in enumerate(models):\n","        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n","        y_eval_cv = train[train[\"fold\"] == fold][target]\n","\n","        pred = model.predict(X_eval_cv)\n","\n","        trues.extend(y_eval_cv)\n","        preds.extend(pred)\n","        \n","    rmse = np.sqrt(mean_squared_error(trues, preds))\n","    print(f\"{target}_rmse : {rmse}\")\n","    rmses = rmses + [rmse]\n","\n","print(f\"mcrmse : {sum(rmses) / len(rmses)}\")\n","model_2_mcrmse = sum(rmses) / len(rmses)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"papermill":{"default_parameters":{},"duration":3904.532124,"end_time":"2023-07-12T20:02:00.433169","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-12T18:56:55.901045","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"006eacd4366548cfaa9ddf17fee7e90f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0594d57c99124f29bafb370ca2e8d00e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38d0446019cd422ca77ee83d6091c33e","placeholder":"​","style":"IPY_MODEL_46481dcde16d4c5a8460ce1dce5bb39a","value":" 7165/7165 [00:02&lt;00:00, 3155.90it/s]"}},"061613ba502c46ed9ef12aa14404c656":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20c4fc3ba85445c6958a54189c1fbad3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2313a820078f410f84b25bd35b3565d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26eba1b0bfad4f1d86e8a8209759a5d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20c4fc3ba85445c6958a54189c1fbad3","placeholder":"​","style":"IPY_MODEL_7aefb7d32bcc43f289602a2fd71e1146","value":"Downloading (…)lve/main/config.json: 100%"}},"2735154e616a469da8524bc5dcd92d1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c91894e264e411a8edea0bebaeec93b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ce22175883048b8a5cad99ebe886800":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e60e876f8054470a29d3249763df1fd","placeholder":"​","style":"IPY_MODEL_eacb98d83fc742959faf04c9f8b54818","value":" 52.0/52.0 [00:00&lt;00:00, 3.55kB/s]"}},"38d0446019cd422ca77ee83d6091c33e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e60e876f8054470a29d3249763df1fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"444e95d1eed548bbb64339cfda3c9e30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fef5ba86e9f48f6bb664be8d3a60dda","placeholder":"​","style":"IPY_MODEL_2c91894e264e411a8edea0bebaeec93b","value":" 579/579 [00:00&lt;00:00, 42.2kB/s]"}},"46481dcde16d4c5a8460ce1dce5bb39a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48f7b44c9bf9414dab534c2150236b00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_524158d9d5bd4d98ba1d3a6320baa641","IPY_MODEL_c9617f1f10a94797b60fb8df656e0218","IPY_MODEL_2ce22175883048b8a5cad99ebe886800"],"layout":"IPY_MODEL_f34c8285422c43ea9e298e05748650ef"}},"524158d9d5bd4d98ba1d3a6320baa641":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9bc6d658e23424c8a553d3f1b373544","placeholder":"​","style":"IPY_MODEL_8578fe21650643748145c6ce56e6a8ac","value":"Downloading (…)okenizer_config.json: 100%"}},"53b4bff155dd4fda9b49d1d0ad08a6a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55008084828c4de3bf617f59873c767d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc9c3cd212ee4e35b1d87e8529ece826","placeholder":"​","style":"IPY_MODEL_afd9c754cb8242f9a5eded75e4c6bf2d","value":" 371M/371M [00:01&lt;00:00, 367MB/s]"}},"556b72893c4e441c922c57510d54dc17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"557f7b1f7e814a8c95848bb7e7c48f12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e72f6946520d4172bac02beee324fc05","IPY_MODEL_78b271b1d17e4d608a474439c19cd0f8","IPY_MODEL_55008084828c4de3bf617f59873c767d"],"layout":"IPY_MODEL_99f53794c1f544f886415080b4f552a5"}},"5e97b6e3c00e4167a68588003e9365e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"610e0a406e504081add04d4593a582ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fef5ba86e9f48f6bb664be8d3a60dda":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"722eb83c79424b3a869d42c5197e61ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"731f0254f3744a148c9c1144330ddaac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"734bb350e7cf48129acd7d95613d0f1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26eba1b0bfad4f1d86e8a8209759a5d6","IPY_MODEL_7d036870db624916be81d8ab66085893","IPY_MODEL_444e95d1eed548bbb64339cfda3c9e30"],"layout":"IPY_MODEL_5e97b6e3c00e4167a68588003e9365e4"}},"77d54f716e884156a93bd0e33a8d357a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78b271b1d17e4d608a474439c19cd0f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff4308df7fa7413aa4d62b80b3d360be","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5c94ce411754b6a9478153e95eaa375","value":371146213}},"7aefb7d32bcc43f289602a2fd71e1146":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d036870db624916be81d8ab66085893":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4dc646ca52b4d15be0388764a62a530","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0335159e02f4bcbaf0ed03e81b37c82","value":579}},"7e668f44f0ab4b0a8314e810d8f5ada8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_731f0254f3744a148c9c1144330ddaac","max":7165,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2735154e616a469da8524bc5dcd92d1f","value":7165}},"837c01c3a677493ca40dab52648f05f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbd0160422974822b71a4458b8dc3b5c","placeholder":"​","style":"IPY_MODEL_b9aa58ad31bc4fab9ff421ddd8b5795c","value":"Downloading spm.model: 100%"}},"8578fe21650643748145c6ce56e6a8ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99f53794c1f544f886415080b4f552a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4dc646ca52b4d15be0388764a62a530":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab33fd12dc2a4879a06d12e32c87a1a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afd9c754cb8242f9a5eded75e4c6bf2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1ee5646c8cb4297a03c2fdef62ac648":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_837c01c3a677493ca40dab52648f05f0","IPY_MODEL_efe88537d2b34c4f9c5ac3bedc2e7427","IPY_MODEL_c4a568f9b9f44c368e4b7ee349780c0f"],"layout":"IPY_MODEL_ab33fd12dc2a4879a06d12e32c87a1a5"}},"b9aa58ad31bc4fab9ff421ddd8b5795c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9bc6d658e23424c8a553d3f1b373544":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc9c3cd212ee4e35b1d87e8529ece826":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bee56aa1633b4f4cbeaf9455c8f7ce65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4a568f9b9f44c368e4b7ee349780c0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53b4bff155dd4fda9b49d1d0ad08a6a6","placeholder":"​","style":"IPY_MODEL_e133e30189934de28ac2ec5746d63e50","value":" 2.46M/2.46M [00:00&lt;00:00, 53.1MB/s]"}},"c9617f1f10a94797b60fb8df656e0218":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77d54f716e884156a93bd0e33a8d357a","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_610e0a406e504081add04d4593a582ca","value":52}},"d85d809ca57b47858875e6ac84c140c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbd0160422974822b71a4458b8dc3b5c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e133e30189934de28ac2ec5746d63e50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3cf208b38db4fdd896dc68af00a03a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bee56aa1633b4f4cbeaf9455c8f7ce65","placeholder":"​","style":"IPY_MODEL_2313a820078f410f84b25bd35b3565d2","value":"100%"}},"e72f6946520d4172bac02beee324fc05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_722eb83c79424b3a869d42c5197e61ce","placeholder":"​","style":"IPY_MODEL_006eacd4366548cfaa9ddf17fee7e90f","value":"Downloading pytorch_model.bin: 100%"}},"eacb98d83fc742959faf04c9f8b54818":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecb9e26c57f1481fad163de50959f8a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3cf208b38db4fdd896dc68af00a03a2","IPY_MODEL_7e668f44f0ab4b0a8314e810d8f5ada8","IPY_MODEL_0594d57c99124f29bafb370ca2e8d00e"],"layout":"IPY_MODEL_061613ba502c46ed9ef12aa14404c656"}},"efe88537d2b34c4f9c5ac3bedc2e7427":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d85d809ca57b47858875e6ac84c140c1","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_556b72893c4e441c922c57510d54dc17","value":2464616}},"f0335159e02f4bcbaf0ed03e81b37c82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f34c8285422c43ea9e298e05748650ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5c94ce411754b6a9478153e95eaa375":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff4308df7fa7413aa4d62b80b3d360be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}
